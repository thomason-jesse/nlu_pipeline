To use this package, first set up your catkin workspace according to the instructions at
https://github.com/utexas-bwi/bwi

Next, navigate to catkin_ws/src/bwi_common/ and checkout the branch with static fact query service implemented:

$ cd catkin_ws/src/bwi_common/
$ git checkout jesse/static_fact_query

Next, set up the nlu_pipeline by navigating to catkin_ws/src and cloning this repository

$ cd ../
$ git clone https://github.com/thomason-jesse/nlu_pipeline.git

Finally, source the terminal and make the package

$ cd ../
$ source devel/setup.bash
$ catkin_make

Running the pipeline is a little different between simulation and the segbot.

SIMULATION:

Launch the segbot simulator.

$ roslaunch bwi_launch simulation.launch

The simulator has to be launched to allow the robot to execute actions given to it in dialoge. It also
launches the ASP knowledge base used to ground predicates such as person(ray).

SEGBOT:

Turn on the base and launch the v2 platform

$ roslaunch bwi_launch segbot_v2.launch

Localize the robot, then launch

$ roslaunch bwi_kr_execution bwi_kr_execution.launch

So that KB facts can be grounded.

TESTING PIPELINE:

In a new tab for catkin_ws/, you can test the pipeline with

$ rosrun nlu_pipeline test_pipeline.py [ontology text file] [lexicon text file] [training text file]

TESTING POMDP:

rosrun nlu_pipeline TestPomdpPipeline.py src/nlu_pipeline/src/resources/asp_actions/ont.txt src/nlu_pipeline/src/resources/asp_actions/lex.txt src/nlu_pipeline/src/resources/asp_actions/utterance_action_pairs.txt

NOTE:
  Right now there will be an initial "testing Generator" prompt. You can skip this by typing "stop".
  This is a result of me not branching the latest component.

TESTING SPEECH RECOGNIZER:

In a new tab for catkin_ws/, the speech recognizer node may be run with:

$ rosrun nlu_pipeline speechRecognizer.py
