To use this package, first set up your catkin workspace according to the instructions at
https://github.com/utexas-bwi/bwi

Next, navigate to catkin_ws/src/bwi_common/ and checkout the branch with static fact query service implemented:

$ cd catkin_ws/src/bwi_common/
$ git checkout jesse/static_fact_query

Next, set up the nlu_pipeline by navigating to catkin_ws/src and cloning this repository

$ cd ../
$ git clone https://github.com/thomason-jesse/nlu_pipeline.git

Finally, source the terminal and make the package

$ cd ../
$ source devel/setup.bash
$ catkin_make

Running the pipeline is a little different between simulation and the segbot.

SIMULATION:

Launch the segbot simulator.

$ roslaunch bwi_launch simulation.launch

The simulator has to be launched to allow the robot to execute actions given to it in dialoge. It also
launches the ASP knowledge base used to ground predicates such as person(ray).

SEGBOT:

Turn on the base and launch the v2 platform

$ roslaunch bwi_launch segbot_v2.launch

Localize the robot, then launch

$ roslaunch bwi_kr_execution bwi_kr_execution.launch

So that KB facts can be grounded.

TESTING PIPELINE:

In a new tab for catkin_ws/, you can test the pipeline with

$ rosrun nlu_pipeline test_pipeline.py [ontology text file] [lexicon text file] [training text file]

rosrun nlu_pipeline test_pipeline.py src/nlu_pipeline/src/resources/fake_to_real/ont.txt src/nlu_pipeline/src/resources/fake_to_real/lex.txt src/nlu_pipeline/src/resources/fake_to_real/utterance_action_pairs.txt

TESTING POMDP:

rosrun nlu_pipeline test_pomdp_pipeline.py src/nlu_pipeline/src/resources/fake_to_real/ont.txt src/nlu_pipeline/src/resources/fake_to_real/lex.txt src/nlu_pipeline/src/resources/fake_to_real/utterance_action_pairs.txt

POMDP AMT Experiment

rosrun nlu_pipeline DialogueServer.py src/nlu_pipeline/src/resources/fake_to_real/ont.txt src/nlu_pipeline/src/resources/fake_to_real/lex.txt src/nlu_pipeline/src/resources/fake_to_real/utterance_action_pairs.txt

Training POMDP :

rosrun nlu_pipeline TrainPomdpPipeline.py src/nlu_pipeline/src/resources/fake_to_real/ont.txt src/nlu_pipeline/src/resources/fake_to_real/lex.txt src/nlu_pipeline/src/resources/fake_to_real/utterance_action_pairs.txt

Rosbridge server:

roslaunch rosbridge_server rosbridge_websocket.launch

NOTE:
  Right now there will be an initial "testing Generator" prompt. You can skip this by typing "stop".
  This is a result of me not branching the latest component.

Format of various logs - 
    1. executed_actions - The file is named as user_id.txt and has a single line containing the final action of the dialogue. 
    2. log - The text of the dialogue, named as user_id.txt.
    3. log_special - Files that contain aggregtae data for an experiment, for example the list of user ids
    4. object_log - This has a pickle named user_id.pkl for each dialogue. The pickle is a tuple with
            - A string : 'static' or 'pomdp' indicating whether a static policy or POMDP policy was used
            - A list of lists, each of which corresponds to a turn. Each turn is a list of
                - The system action of type SystemAction or a string 'take_action'
                - The text of the user response (None if the previous system action is of action_type 'take_action')
            - The final action understood, of type Action
            - Train data for the parser. This is a dict with keys
                - full - Text corresponding to a complete action
                - <param_name> - Value for the parameter <param_name>. Currently the parameter names in use are patient, recipient and location

            


